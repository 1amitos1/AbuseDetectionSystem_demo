{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 782723918692804825\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4401690754677292438\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15782644941\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9762594069106496033\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5923915520383946777\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import cv2\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras import backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
    "        # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.data_aug = data_augmentation\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data() \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "        \n",
    "    def search_data(self):\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path,file)\n",
    "                # append the each file path, and keep its label  \n",
    "                X_path.append(file_path)\n",
    "                Y_dict[file_path] = one_hots[i]\n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    def print_stats(self):\n",
    "        # calculate basic information\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the data of each batch\n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle the data at each end of epoch\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def data_generation(self, batch_path):\n",
    "        # load data into memory, you can change the np.load to any method you want\n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "      \n",
    "    def normalize(self, data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        return (data-mean) / std\n",
    "    \n",
    "    def random_flip(self, video, prob):\n",
    "        s = np.random.rand()\n",
    "        if s < prob:\n",
    "            video = np.flip(m=video, axis=2)\n",
    "        return video    \n",
    "    \n",
    "    def uniform_sampling(self, video, target_frames=64):\n",
    "        # get total frames of input video and calculate sampling interval \n",
    "        len_frames = int(len(video))\n",
    "        interval = int(np.ceil(len_frames/target_frames))\n",
    "        # init empty list for sampled video and \n",
    "        sampled_video = []\n",
    "        for i in range(0,len_frames,interval):\n",
    "            sampled_video.append(video[i])     \n",
    "        # calculate numer of padded frames and fix it \n",
    "        num_pad = target_frames - len(sampled_video)\n",
    "        padding = []\n",
    "        if num_pad>0:\n",
    "            for i in range(-num_pad,0):\n",
    "                try: \n",
    "                    padding.append(video[i])\n",
    "                except:\n",
    "                    padding.append(video[0])\n",
    "            sampled_video += padding     \n",
    "        # get sampled video\n",
    "        return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "    def random_clip(self, video, target_frames=64):\n",
    "        start_point = np.random.randint(len(video)-target_frames)\n",
    "        return video[start_point:start_point+target_frames]\n",
    "    \n",
    "    def dynamic_crop(self, video):\n",
    "        # extract layer of optical flow from video\n",
    "        opt_flows = video[...,3]\n",
    "        # sum of optical flow magnitude of individual frame\n",
    "        magnitude = np.sum(opt_flows, axis=0)\n",
    "        # filter slight noise by threshold \n",
    "        thresh = np.mean(magnitude)\n",
    "        magnitude[magnitude<thresh] = 0\n",
    "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "        # normalize PDF of x and y so that the sum of probs = 1\n",
    "        x_pdf /= np.sum(x_pdf)\n",
    "        y_pdf /= np.sum(y_pdf)\n",
    "        # randomly choose some candidates for x and y \n",
    "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "        # get the mean of x and y coordinates for better robustness\n",
    "        x = int(np.mean(x_points))\n",
    "        y = int(np.mean(y_points))\n",
    "        # avoid to beyond boundaries of array\n",
    "        x = max(56,min(x,167))\n",
    "        y = max(56,min(y,167))\n",
    "        # get cropped video \n",
    "        return video[:,x-56:x+56,y-56:y+56,:]  \n",
    "    \n",
    "    def color_jitter(self,video):\n",
    "        # range of s-component: 0-1\n",
    "        # range of v component: 0-255\n",
    "        s_jitter = np.random.uniform(-0.2,0.2)\n",
    "        v_jitter = np.random.uniform(-30,30)\n",
    "        for i in range(len(video)):\n",
    "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "            s = hsv[...,1] + s_jitter\n",
    "            v = hsv[...,2] + v_jitter\n",
    "            s[s<0] = 0\n",
    "            s[s>1] = 1\n",
    "            v[v<0] = 0\n",
    "            v[v>255] = 255\n",
    "            hsv[...,1] = s\n",
    "            hsv[...,2] = v\n",
    "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return video\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "        data = np.load(path, mmap_mode='r')\n",
    "        data = np.float32(data)\n",
    "        # sampling 64 frames uniformly from the entire video\n",
    "        data = self.uniform_sampling(video=data, target_frames=64)\n",
    "        # whether to utilize the data augmentation\n",
    "        if  self.data_aug:\n",
    "            data[...,:3] = self.color_jitter(data[...,:3])\n",
    "            data = self.random_flip(data, prob=0.5)\n",
    "        # normalize rgb images and optical flows, respectively\n",
    "        data[...,:3] = self.normalize(data[...,:3])\n",
    "        data[...,3:] = self.normalize(data[...,3:])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 64, 224, 224, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 64, 224, 224, 0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 64, 224, 224, 0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_133 (Conv3D)             (None, 64, 224, 224, 448         lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_141 (Conv3D)             (None, 64, 224, 224, 304         lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_134 (Conv3D)             (None, 64, 224, 224, 784         conv3d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_142 (Conv3D)             (None, 64, 224, 224, 784         conv3d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_73 (MaxPooling3D) (None, 64, 112, 112, 0           conv3d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_77 (MaxPooling3D) (None, 64, 112, 112, 0           conv3d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_135 (Conv3D)             (None, 64, 112, 112, 2320        max_pooling3d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_143 (Conv3D)             (None, 64, 112, 112, 2320        max_pooling3d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_136 (Conv3D)             (None, 64, 112, 112, 784         conv3d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_144 (Conv3D)             (None, 64, 112, 112, 784         conv3d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_74 (MaxPooling3D) (None, 64, 56, 56, 1 0           conv3d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_78 (MaxPooling3D) (None, 64, 56, 56, 1 0           conv3d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_137 (Conv3D)             (None, 64, 56, 56, 3 4640        max_pooling3d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_145 (Conv3D)             (None, 64, 56, 56, 3 4640        max_pooling3d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_138 (Conv3D)             (None, 64, 56, 56, 3 3104        conv3d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_146 (Conv3D)             (None, 64, 56, 56, 3 3104        conv3d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_75 (MaxPooling3D) (None, 64, 28, 28, 3 0           conv3d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_79 (MaxPooling3D) (None, 64, 28, 28, 3 0           conv3d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_139 (Conv3D)             (None, 64, 28, 28, 3 9248        max_pooling3d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_147 (Conv3D)             (None, 64, 28, 28, 3 9248        max_pooling3d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_140 (Conv3D)             (None, 64, 28, 28, 3 3104        conv3d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_148 (Conv3D)             (None, 64, 28, 28, 3 3104        conv3d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_76 (MaxPooling3D) (None, 64, 14, 14, 3 0           conv3d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_80 (MaxPooling3D) (None, 64, 14, 14, 3 0           conv3d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 64, 14, 14, 3 0           max_pooling3d_76[0][0]           \n",
      "                                                                 max_pooling3d_80[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_81 (MaxPooling3D) (None, 8, 14, 14, 32 0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_149 (Conv3D)             (None, 8, 14, 14, 64 18496       max_pooling3d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_150 (Conv3D)             (None, 8, 14, 14, 64 12352       conv3d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_82 (MaxPooling3D) (None, 4, 7, 7, 64)  0           conv3d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_151 (Conv3D)             (None, 4, 7, 7, 64)  36928       max_pooling3d_82[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_152 (Conv3D)             (None, 4, 7, 7, 64)  12352       conv3d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_83 (MaxPooling3D) (None, 2, 3, 3, 64)  0           conv3d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_153 (Conv3D)             (None, 2, 3, 3, 128) 73856       max_pooling3d_83[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_154 (Conv3D)             (None, 2, 3, 3, 128) 49280       conv3d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_84 (MaxPooling3D) (None, 1, 1, 1, 128) 0           conv3d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 128)          0           max_pooling3d_84[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          16512       flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 32)           4128        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            66          dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 272,690\n",
      "Trainable params: 272,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Found 1600 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Found 400 files belonging to 2 classes.\n",
      "     Fight :  0\n",
      "  NonFight :  1\n",
      "Epoch 1/5\n",
      "267/267 [==============================] - 310s 1s/step - loss: 0.6886 - accuracy: 0.5638 - val_loss: 0.5646 - val_accuracy: 0.6750\n",
      "Epoch 2/5\n",
      "267/267 [==============================] - 294s 1s/step - loss: 0.6103 - accuracy: 0.6875 - val_loss: 0.3865 - val_accuracy: 0.8125\n",
      "Epoch 3/5\n",
      "267/267 [==============================] - 305s 1s/step - loss: 0.5502 - accuracy: 0.7375 - val_loss: 0.6318 - val_accuracy: 0.5525\n",
      "Epoch 4/5\n",
      "267/267 [==============================] - 304s 1s/step - loss: 0.5528 - accuracy: 0.7400 - val_loss: 0.2551 - val_accuracy: 0.8100\n",
      "Epoch 5/5\n",
      "127/267 [=============>................] - ETA: 2:10 - loss: 0.4831 - accuracy: 0.7763"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.layers.core import Lambda\n",
    "import numpy as np\n",
    "# extract the rgb images \n",
    "def get_rgb(input_x):\n",
    "    rgb = input_x[...,:3]\n",
    "    return rgb\n",
    "\n",
    "# extract the optical flows\n",
    "def get_opt(input_x):\n",
    "    opt= input_x[...,3:5]\n",
    "    return opt\n",
    "\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    inputs = Input(shape=(64,224,224,5))\n",
    "    rgb = Lambda(get_rgb,output_shape=None)(inputs)\n",
    "    opt = Lambda(get_opt,output_shape=None)(inputs)\n",
    "\n",
    "    ##################################################### RGB channel\n",
    "    rgb = Conv3D(\n",
    "        16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = Conv3D(\n",
    "        16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "    rgb = Conv3D(\n",
    "        16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = Conv3D(\n",
    "        16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "    rgb = Conv3D(\n",
    "        32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = Conv3D(\n",
    "        32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "    rgb = Conv3D(\n",
    "        32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = Conv3D(\n",
    "        32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "    rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "    ##################################################### Optical Flow channel\n",
    "    opt = Conv3D(\n",
    "        16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "    opt = Conv3D(\n",
    "        16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "    opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "    opt = Conv3D(\n",
    "        16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "    opt = Conv3D(\n",
    "        16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "    opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "    opt = Conv3D(\n",
    "        32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "    opt = Conv3D(\n",
    "        32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "    opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "    opt = Conv3D(\n",
    "        32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "    opt = Conv3D(\n",
    "        32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "    opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "\n",
    "    ##################################################### Fusion and Pooling\n",
    "    x = Multiply()([rgb,opt])\n",
    "    x = MaxPooling3D(pool_size=(8,1,1))(x)\n",
    "\n",
    "    ##################################################### Merging Block\n",
    "    x = Conv3D(\n",
    "        64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "    x = Conv3D(\n",
    "        64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "    x = Conv3D(\n",
    "        64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "    x = Conv3D(\n",
    "        64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "    x = Conv3D(\n",
    "        128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "    x = Conv3D(\n",
    "        128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D(pool_size=(2,3,3))(x)\n",
    "\n",
    "    ##################################################### FC Layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "\n",
    "    # Build the model\n",
    "    pred = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=pred)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "   \n",
    "    #adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
    " \n",
    "    \n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    batch_size  = 8\n",
    "    train_generator = DataGenerator(directory='/root/home/rwf_2000_np/train',batch_size=batch_size,data_augmentation=True)                            \n",
    "    val_generator = DataGenerator(directory='/root/home/rwf_2000_np/val', batch_size=batch_size,data_augmentation=False)\n",
    "    return train_generator,val_generator\n",
    "                            \n",
    "\n",
    "    \n",
    "####################################################################3\n",
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "    #if epoch  == 1 and epoch != 0:\n",
    "    #print(\"---------------in scheduler-----------------------\")\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.7)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)    \n",
    "\n",
    "model = get_compiled_model()\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "class MyCbk(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "         self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save('/root/home/Log/model_at_epoch_%d.h5' % (epoch+1))\n",
    "\n",
    "check_point = MyCbk(model)\n",
    "\n",
    "\n",
    "filename = '/root/home/Log/ours_log.csv'\n",
    "csv_logger = CSVLogger(filename, separator=',', append=True)\n",
    "callbacks_list = [check_point, csv_logger, reduce_lr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_epochs  = 30\n",
    "num_workers = 16\n",
    "batch_size  = 6\n",
    "\n",
    "train_generator = DataGenerator(directory='/root/home/RWF_2000_NP/train',batch_size=batch_size,data_augmentation=True)                            \n",
    "val_generator = DataGenerator(directory='/root/home/RWF_2000_NP/val', batch_size=batch_size,data_augmentation=True)\n",
    "\n",
    "\n",
    "\n",
    "hist = model.fit_generator(\n",
    "    generator=train_generator, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1, \n",
    "    epochs=num_epochs,\n",
    "    workers=num_workers ,\n",
    "    max_queue_size=4,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}